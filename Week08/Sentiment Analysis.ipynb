{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Importing the libraries\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer\n# To count the iterations \nfrom tqdm import tqdm\n# Importing the dataset\ndataset = pd.read_csv('Reviews.csv')\ndataset.info()\ndataset.head()\n# Dropping the dups in dataset\ndataset = dataset.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n#dataset\n# Dropping the dups in dataset\ndataset = dataset.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n#dataset\n#removing HTML tags\ndef removeHTMLTags(review):\n    soup = BeautifulSoup(review, 'lxml')\n    return soup.get_text()\n#removing punctuations from the text\ndef removeApostrophe(review):\n    phrase = re.sub(r\"won't\", \"will not\", review)\n    phrase = re.sub(r\"can\\'t\", \"can not\", review)\n    phrase = re.sub(r\"n\\'t\", \" not\", review)\n    phrase = re.sub(r\"\\'re\", \" are\", review)\n    phrase = re.sub(r\"\\'s\", \" is\", review)\n    phrase = re.sub(r\"\\'d\", \" would\", review)\n    phrase = re.sub(r\"\\'ll\", \" will\", review)\n    phrase = re.sub(r\"\\'t\", \" not\", review)\n    phrase = re.sub(r\"\\'ve\", \" have\", review)\n    phrase = re.sub(r\"\\'m\", \" am\", review)\n     return phrase\n#To remove Special Characters\ndef removeAlphaNumericWords(review):\n     return re.sub(\"\\S*\\d\\S*\", \"\", review).strip()\n#To remove Special Characters\ndef removeSpecialChars(review):\n     return re.sub('[^a-zA-Z]', ' ', review)\n    def scorePartition(x):\n    if x < 3:\n        return 0\n    return 1\ndef doTextCleaning(review):\n    review = removeHTMLTags(review)\n    review = removeApostrophe(review)\n    review = removeAlphaNumericWords(review)\n    review = removeSpecialChars(review) \n    # Lower casing\n    review = review.lower()  \n    #Tokenization\n    review = review.split()\n    #Removing Stopwords and Lemmatization\n    lmtzr = WordNetLemmatizer()\n    review = [lmtzr.lemmatize(word, 'v') for word in review if not word in set(stopwords.words('english'))]\n    review = \" \".join(review)    \n    return review\n# Generalizing the score\nactualScore = dataset['Score']\npositiveNegative = actualScore.map(scorePartition) \ndataset['Score'] = positiveNegative\n# creating the document corpus\ncorpus = []   \nfor index, row in tqdm(dataset.iterrows()):\n    review = doTextCleaning(row['Text'])\n    corpus.append(review)\n    # Creating the Bag of Words model\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Creating a tranform\ncv = CountVectorizer(ngram_range=(1,3), max_features = 5000)\nX = cv.fit_transform(corpus).toarray()\ny = dataset.iloc[:,6].values\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n\n# Fitting Naive Bayes to the Training set\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n#Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n# Predict the sentiment for new review\ndef predictNewReview():\n    newReview = input(\"Type the Review: \")\n    \n    if newReview =='':\n        print('Invalid Review')  \n    else:\n        newReview = doTextCleaning(newReview)\n        new_review = cv.transform([newReview]).toarray()  \n        prediction =  classifier.predict(new_review)\n        print(prediction)\n        if prediction[0] == 1:\n            print( \"Positive Review\" )\n        else:\n            \n            print( \"Negative Review\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}